syntax = 'proto3';
package gooseai;
option go_package = "github.com/stability-ai/api-interfaces/gooseai/generation";
import "tensors.proto";

enum FinishReason {
  NULL = 0;
  LENGTH = 1;
  STOP = 2;
  ERROR = 3;
  FILTER = 4;
}

enum ArtifactType {
  ARTIFACT_NONE = 0;
  ARTIFACT_IMAGE = 1;
  ARTIFACT_VIDEO = 2;
  ARTIFACT_TEXT = 3;
  ARTIFACT_TOKENS = 4;
  ARTIFACT_EMBEDDING = 5;
  ARTIFACT_CLASSIFICATIONS = 6;
  ARTIFACT_MASK = 7;
  ARTIFACT_LATENT = 8;
  ARTIFACT_TENSOR = 9;
  ARTIFACT_LORA = 500;
  ARTIFACT_DEPTH = 501;
}

// Generally, a GPT BPE 16-bit token, paired with an optional string representation.
message Token {
  optional string text = 1;
  uint32 id = 2;
}

// Sequence of tokens, paired with the id of the tokenizer used to generate them.
message Tokens {
  repeated Token tokens = 1;
  optional string tokenizer_id = 2;
}

enum GaussianDirection {
  DIRECTION_NONE = 0;
  DIRECTION_UP = 1;
  DIRECTION_DOWN = 2;
}

message ImageAdjustment_Gaussian {
  float sigma = 1;
  GaussianDirection direction = 2;
}

message ImageAdjustment_Invert{
}

message ImageAdjustment_Levels {
  float input_low = 1;
  float input_high = 2;
  float output_low = 3;
  float output_high = 4;
}

enum ChannelSource {
  CHANNEL_R = 0;
  CHANNEL_G = 1;
  CHANNEL_B = 2;
  CHANNEL_A = 3;
  CHANNEL_ZERO = 4;
  CHANNEL_ONE = 5;
  CHANNEL_DISCARD = 6;
}

message ImageAdjustment_Channels {
  optional ChannelSource r = 1;
  optional ChannelSource g = 2;
  optional ChannelSource b = 3;
  optional ChannelSource a = 4;
}

enum RescaleMode {
  RESCALE_STRICT = 0;
  // Completely cover the rescale height and width, maintaining aspect ratio, cropping any extra
  RESCALE_COVER = 2;
  // Fit the complete source image into the rescale height and width, maintaining aspect ratio, background to be filled with zeros
  RESCALE_CONTAIN_ZERO = 3;
  // Fit the complete source image into the rescale height and width, maintaining aspect ratio, background to be filled with the edge of the image repeating
  RESCALE_CONTAIN_REPLICATE = 4;
  // Fit the complete source image into the rescale height and width, maintaining aspect ratio, background to be filled with the image mirrored
  RESCALE_CONTAIN_REFLECT = 5;
}

message ImageAdjustment_Rescale {
  uint64 height = 1;
  uint64 width = 2;
  RescaleMode mode = 3;
  repeated string algorithm_hint = 4;
}

message ImageAdjustment_Crop {
  uint64 top = 1;
  uint64 left = 2;
  uint64 width = 3;
  uint64 height = 4;
}

message ImageAdjustment_Depth {
  // You can provide a list of depth engine ID preferences, first match will be used,
  // or default engine if no match
  repeated string depth_engine_hint = 1; 
}

message ImageAdjustment {
  oneof adjustment {
    ImageAdjustment_Gaussian blur = 1;
    ImageAdjustment_Invert invert = 2;
    ImageAdjustment_Levels levels = 3;
    ImageAdjustment_Channels channels = 4;
    ImageAdjustment_Rescale rescale = 5;
    ImageAdjustment_Crop crop = 6;
    ImageAdjustment_Depth depth = 7;
  }
}

message SafetensorsMeta {
  string key = 1;
  string value = 2;
}

message SafetensorsTensor {
  string key = 1;
  tensors.Tensor tensor = 2;
}

message Safetensors {
  repeated SafetensorsMeta metadata = 1;
  repeated SafetensorsTensor tensors = 2;
}

message LoraWeight {
  string model_name = 1;
  float weight = 2;
}

message Lora {
  Safetensors lora = 1;
  repeated LoraWeight weights = 2;
}

enum ArtifactStage {
  ARTIFACT_BEFORE_ADJUSTMENTS = 0;
  ARTIFACT_AFTER_ADJUSTMENTS = 1;
  ARTIFACT_AFTER_POSTADJUSTMENTS = 2;
}

message ArtifactReference {
  oneof reference {
    uint64 id = 1;
    string uuid = 2;
  }
  ArtifactStage stage = 3;
}

// A tangible Artifact, such as an image, video, or text that is used for input
// or output.
message Artifact {
  uint64 id = 1;
  ArtifactType type = 2;
  string mime = 3;                // MIME type identifier, e.g. "image/png"
  optional string magic = 4;      // Magic number, e.g. "PNG"
  oneof data {
    bytes binary = 5;             // Binary data, e.g. PNG image
    string text = 6;              // Text data, e.g. text prompt
    Tokens tokens = 7;            // Tokenized text data, e.g. GPT tokens
    ClassifierParameters classifier = 11;
    tensors.Tensor tensor = 14;   // torch.Tensor:
                                  //    RGB tensor (C,H,W)
                                  //    VAE latent (C,H//8,W//8, assuming VAE-f8)
    Lora lora = 510;              // A Lora embedding
    ArtifactReference ref = 511;  // A reference to a previous Artifact
  }
  uint32 index = 8;               // Index of this artifact in input/output list
  FinishReason finish_reason = 9; // Reason for finishing, if applicable
  uint32 seed = 10;               // Seed used to generate this artifact
  string uuid = 12;               // UUIDv4 of the artifact, used for asset lookup
  uint64 size = 13;               // Size of the artifact in bytes

  repeated ImageAdjustment adjustments = 500; // Adjustments to this image / mask before generation
  repeated ImageAdjustment postAdjustments = 501; // Adjustments to this image / mask after generation
}

enum MaskedAreaInit {
  MASKED_AREA_INIT_ZERO = 0;
  MASKED_AREA_INIT_RANDOM = 1;
  MASKED_AREA_INIT_ORIGINAL = 2;
}

enum WeightMethod {
  TEXT_ENCODER = 0;
  CROSS_ATTENTION = 1;
}

// A set of parameters for each individual Prompt.
message PromptParameters {
  optional bool init = 1;
  optional float weight = 2;
}

// A Prompt is a special type of Artifact that is used to generate an output.
// There can be multiple Prompts that affect the same output. Currently, the
// only Prompts supported are:
//   - Text (singular)
//   - Init Image (singular, optional, type ARTIFACT_IMAGE, with init=true)
//   - Mask (singular, optional, Artifact type ARTIFACT_MASK)
// .
message Prompt {
  optional PromptParameters parameters = 1;
  oneof prompt {
    string text = 2;
    Tokens tokens = 3;
    Artifact artifact = 4;
  }
}

// DiffusionSampler identifies which sampler to use for Diffusion, and represents
// the internal set of supported samplers.
enum DiffusionSampler {
  SAMPLER_DDIM = 0;
  SAMPLER_DDPM = 1;
  SAMPLER_K_EULER = 2;
  SAMPLER_K_EULER_ANCESTRAL = 3;
  SAMPLER_K_HEUN = 4;
  SAMPLER_K_DPM_2 = 5;
  SAMPLER_K_DPM_2_ANCESTRAL = 6;
  SAMPLER_K_LMS = 7;
  SAMPLER_K_DPMPP_2S_ANCESTRAL = 8;
  SAMPLER_K_DPMPP_2M = 9;
  SAMPLER_K_DPMPP_SDE = 10;

  SAMPLER_DPMSOLVERPP_1ORDER = 500;
  SAMPLER_DPMSOLVERPP_2ORDER = 501;
  SAMPLER_DPMSOLVERPP_3ORDER = 502;

  SAMPLER_DPM_FAST = 550;
  SAMPLER_DPM_ADAPTIVE = 551;
  // Deprecated - use the official value above
  SAMPLER_DPMSOLVERPP_2S_ANCESTRAL = 552;
  // Deprecated - use the official value above
  SAMPLER_DPMSOLVERPP_SDE = 553;
  // Deprecated - use the official value above
  SAMPLER_DPMSOLVERPP_2M = 554;
}

message SigmaParameters {
  optional float sigma_min = 1;
  optional float sigma_max = 2;
  optional float karras_rho = 10;
}

message ChurnSettings {
  float churn = 1;
  optional float churn_tmin = 2;
  optional float churn_tmax = 3;
}

enum SamplerNoiseType {
  SAMPLER_NOISE_NORMAL = 0;
  SAMPLER_NOISE_BROWNIAN = 1;
}

// Parameters that affect the behavior of the sampler, typically used for CFG.
message SamplerParameters {
  optional float eta = 1;
  optional uint64 sampling_steps = 2;
  optional uint64 latent_channels = 3;
  optional uint64 downsampling_factor = 4;
  optional float cfg_scale = 5;
  optional float init_noise_scale = 6; // defaults to 0.99
  optional float step_noise_scale = 7; // defaults to 0.99

  optional ChurnSettings churn = 500;
  optional SigmaParameters sigma = 501;
  optional SamplerNoiseType noise_type = 502;
}

// Unused, but reserved for future use. Adjustments to the latents after
// initialization.
message ConditionerParameters {
  optional string vector_adjust_prior = 1;
  optional Model conditioner = 2;
}

// Future, unimplemented.
enum Upscaler {
  UPSCALER_RGB = 0;
  UPSCALER_GFPGAN = 1;
  UPSCALER_ESRGAN = 2;
}

// When does this schedule definition apply?.
message ScheduleParameters {
  optional float start = 1;     // 0.0 to 1.0
  optional float end = 2;       // 0.0 to 1.0
  optional float value = 3;     // float value to apply on this schedule
}

// Parameters that apply to this block of the schedule.
message StepParameter {
  float scaled_step = 1;
  optional SamplerParameters sampler = 2;
  optional ScheduleParameters schedule = 3;
  optional GuidanceParameters guidance = 4;
}

// Presets for CLIP guidance.
enum GuidancePreset {
  GUIDANCE_PRESET_NONE = 0;
  GUIDANCE_PRESET_SIMPLE = 1;
  GUIDANCE_PRESET_FAST_BLUE = 2;
  GUIDANCE_PRESET_FAST_GREEN = 3;
  GUIDANCE_PRESET_SLOW = 4;
  GUIDANCE_PRESET_SLOWER = 5;
  GUIDANCE_PRESET_SLOWEST = 6;
}

enum ModelArchitecture {
  MODEL_ARCHITECTURE_NONE = 0;
  MODEL_ARCHITECTURE_CLIP_VIT = 1;
  MODEL_ARCHITECTURE_CLIP_RESNET = 2;
  MODEL_ARCHITECTURE_LDM = 3;
}

message Model {
  ModelArchitecture architecture = 1;
  string publisher = 2;
  string dataset = 3;
  float version = 4;
  string semantic_version = 5;
  string alias = 6;
}

message CutoutParameters {
  repeated CutoutParameters cutouts = 1;    // Nested cutouts, unsupported
  optional uint32 count = 2;                // 0 to n, usually 8 to 32, 0 inner
  optional float gray = 3;                       // 0.0 to 1.0, defaults to 0.2
  optional float blur = 4;                       // percentage of cutouts to blur
  optional float size_power = 5;            // defaults to inner: 0.5, outer: 0.0
}

// GuidanceScheduleParameters are used to define a schedule for CLIP guidance, and
// are used to define the behavior of the guidance over time. They are relative
// to the total number of steps, and are scaled to the number of steps in the
// current run.
message GuidanceScheduleParameters {
  float duration = 1;
  float value = 2;
}

// Parameters that affect the behavior of the guidance, typically used for CLIP.
// We can specify more than one model, and the guidance will be a weighted sum
// of the models.
message GuidanceInstanceParameters {
  repeated Model models = 2;                // models to use for this set
  optional float guidance_strength = 3;     // 0.0 to 1.0, usually 0.05 to 0.225
  repeated GuidanceScheduleParameters schedule = 4; // when to apply guidance
  optional CutoutParameters cutouts = 5;    // cutout parameters
  optional Prompt prompt = 6;               // prompt to use for guidance
}

// Parameters that affect the behavior of the guidance, typically used for CLIP.
// The omission of this field implies the default guidance of CFG.
message GuidanceParameters {
  GuidancePreset guidance_preset = 1;                // base preset for guidance
  repeated GuidanceInstanceParameters instances = 2; // guidance instances
}

message TransformType {
  oneof type {
    DiffusionSampler diffusion = 1;
    Upscaler upscaler = 2;
  }
}

message ExtendedParameter {
  string name = 1;
  oneof value {
    float float = 2;
    uint64 int = 3;
    string str = 4;
  }
}

message ExtendedParameters {
  repeated ExtendedParameter parameters = 1;
}

// Parameters that control the hires fix feature.
message HiresFixParameters {
  bool enable = 1;                 // Should it be enabled at all
  optional float oos_fraction = 2; // How out-of-square will we allow the fixed area to be, 0...1
}

message ImageParameters {
  optional uint64 height = 1;
  optional uint64 width = 2;
  repeated uint32 seed = 3;
  optional uint64 samples = 4;
  optional uint64 steps = 5;
  optional TransformType transform = 6;
  repeated StepParameter parameters = 7;
  optional MaskedAreaInit masked_area_init = 8; // defaults to MASKED_AREA_INIT_ZERO 
  optional WeightMethod weight_method = 9; //defaults to TEXT_ENCODER
  optional bool quantize = 10; //defaults to true

  optional ExtendedParameters extension = 500;
  optional HiresFixParameters hires = 510;
  optional bool tiling = 520;
  optional bool tiling_x = 521; // The specific axis override tiling if both set
  optional bool tiling_y = 522;
}

enum Action {
  ACTION_PASSTHROUGH = 0;
  ACTION_REGENERATE_DUPLICATE = 1;
  ACTION_REGENERATE = 2;
  ACTION_OBFUSCATE_DUPLICATE = 3;
  ACTION_OBFUSCATE = 4;
  ACTION_DISCARD = 5;
}

//
// Artifact classification parameters.
//

// Classifier Mode.
enum ClassifierMode {
  CLSFR_MODE_ZEROSHOT = 0;
  CLSFR_MODE_MULTICLASS = 1;
  /*CLSFR_MODE_ODDSRATIO = 2;*/
}

message ClassifierConcept {
  string concept = 1;
  optional float threshold = 2;
}

message ClassifierCategory {
  string name = 1;
  repeated ClassifierConcept concepts = 2;
  optional float adjustment = 3;
  optional Action action = 4;
  optional ClassifierMode classifier_mode = 5;
}

message ClassifierParameters {
  repeated ClassifierCategory categories = 1;
  repeated ClassifierCategory exceeds = 2;
  optional Action realized_action = 3;
}

//
// Asset parameters
//

enum AssetAction {
  ASSET_PUT = 0;
  ASSET_GET = 1;
  ASSET_DELETE = 2;
}

// AssetUse defines how the asset is used within a project.  This enum matches
// the values the project proto.
enum AssetUse {
  ASSET_USE_UNDEFINED = 0;    // Asset does not have use defined
  ASSET_USE_INPUT = 1;        // Asset is used as an input for the project
  ASSET_USE_OUTPUT = 2;       // Asset is an output from the project 
  ASSET_USE_INTERMEDIATE = 3; // Asset is an output from an intermediate step of the project
  ASSET_USE_PROJECT = 4;      // Asset is used as the project file for the project
}

message AssetParameters {
  AssetAction action = 1;
  string project_id = 2;
  AssetUse use = 3;
}

// AnswerMeta is a set of metadata about an answer, usually the operating
// environment.
message AnswerMeta {
  optional string gpu_id = 1;
  optional string cpu_id = 2;
  optional string node_id = 3;
  optional string engine_id = 4;
}

// An Answer is a response to a Request. It is a set of Artifacts, which can be
// of any type and forwarded to the client or the next stage.
message Answer {
  string answer_id = 1;
  string request_id = 2;
  uint64 received = 3;
  uint64 created = 4;
  optional AnswerMeta meta = 6;
  repeated Artifact artifacts = 7;
}

// A Request is a set of Artifacts, which can be of any type with model or
// transform parameters. It is sent to the server, which will respond with an
// Answer.
message Request {
  string engine_id = 1;
  string request_id = 2;
  ArtifactType requested_type = 3;
  repeated Prompt prompt = 4;
  oneof params {
    ImageParameters image = 5;
    ClassifierParameters classifier = 7;
    AssetParameters asset = 8;
  }
  optional ConditionerParameters conditioner = 6;
  reserved 9,10; //9, 10 are reserved
}

//
// Stages
//
// A Stage is a single step in a pipeline. Stages are a set of Requests, which are
// sent to the server, and a set of Answers, which are received from the server.

enum StageAction {
  STAGE_ACTION_PASS = 0;
  STAGE_ACTION_DISCARD = 1;
  STAGE_ACTION_RETURN = 2;
}

message OnStatus {
  repeated FinishReason reason = 1;
  optional string target = 2;
  repeated StageAction action = 3;
}

message Stage {
  string id = 1;
  Request request = 2;
  repeated OnStatus on_status = 3;
}

message ChainRequest {
  string request_id = 1;
  repeated Stage stage = 2;
}

// The status of an async job. 
// Mirrors google.rpc.Status but avoids needing to include that file in the repo.
message AsyncStatus {
  // The status code, which should be an enum value of google.rpc.Code
  int32 code = 1;
  // Any message
  string message = 2;
}

// A potentially partial answer to an AsyncGenerate request, returned by AsyncResult.
message AsyncAnswer {
  // Any completed Answers that have not been returned by a previous call to AsyncResult.
  repeated Answer answer = 1;
  // Is this AsyncGenerate request complete? 
  // (Once true, any further requests will give an error).
  bool complete = 2;
  // Final status. Only set when complete == True.
  AsyncStatus status = 3;
}

// A handle to refer to a AsyncGenerate request.
message AsyncHandle {
  // The request_id for the original Request.
  string request_id = 1;
  // The opaque handle needed to refer to the same AsyncGenerate request.
  string async_handle = 2;
}

message AsyncCancelAnswer {
}

//
// gRPC services
//
service GenerationService {
  rpc Generate (Request) returns (stream Answer) {};
  rpc ChainGenerate (ChainRequest) returns (stream Answer) {};

  /*AsyncGenerate starts an asynchronous generation

  The passed Request is the same as to Generate. However this method
  will return immediately, returning a handle that can be used to get
  any results of the generation created so far or cancel it.*/
  rpc AsyncGenerate (Request) returns (AsyncHandle) {};

  /*AsyncResult gets and results so far for an asynchronous generation
  
  You can call this multiple times. Each time you call it, you will get
  any results that are ready that have not been returned before.
  (Note that this "consumes" the ready results - they will not be returned again).
  
  Any generated results will eventually (default: after 10 minutes) be discarded
  if they are not taken by a call to this method.*/
  rpc AsyncResult (AsyncHandle) returns (AsyncAnswer) {};

  /*AsyncCancel cancels a generation that is currently in progress
  and discards any results that have not yet been returned by a call to AsyncResult.*/
  rpc AsyncCancel (AsyncHandle) returns (AsyncCancelAnswer) {};
}
